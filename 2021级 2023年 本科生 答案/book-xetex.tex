\documentclass[12pt,a4paper,openany,twoside]{ctexbook}
\input{setup/package.tex}   %引用宏包所在位置
\input{setup/format.tex}    %格式所在位置
\input{setup/math_symbol}
\input{setup/refer}

\begin{document}

\setcounter{chapter}{1}
\chapter*{2021级华东师范大学本科生期末考试}
\section*{《数据科学与工程数学基础》笔试试卷 \qquad 2023.2}
\begin{center}
	学院：数据科学与工程学院 \qquad 考试形式：闭卷 \qquad 所需时间：120分钟
\end{center}
\begin{center}
	考生姓名：\underline{~~~~~~}\underline{~~~~~~}\qquad 学号：\underline{~~~~~~}\underline{~~~~~~}\qquad 专业：\underline{~~~~~~}\underline{~~~~~~}\qquad 任课教师：黄定江
\end{center}
{ \begin{center}
		\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|}
			\hline 
			题目 & 一 & 二 & 三 & 四 & 五 & 六 & 七 & 八&总分 \\ 
			\hline 
			满分 & 13 & 12 & 12 & 13 & 13 & 12 & 13 & 12 & 100  \\ 
			\hline 
			得分 &  &  &  &  &  &  &  & &  \\ 
			\hline 
			阅卷人 &  &  &  &  &  &  &  & &  \\ 
			\hline 
		\end{tabular} 
		
\end{center}}

\begin{exercise}(13')
	假设 $Q \in \mathbb{R}^{n \times n} \backslash\{0\}$ 是一个投影矩阵.\\
	\begin{itemize}
		\item [(1)] 证明：$Q z=z, \ \forall z \in \mathcal{R}(Q)$以及$Q y-y \in \mathcal{N}(Q), \ \forall y \in \mathbb{R}^n$.
		\item [(2)] 证明：$Q$的特征值$\lambda \in \Lambda(Q) \subseteq\{0,1\}$。
		\item [(3)]  假设$\mathcal{R}(Q)=\operatorname{span}\left(u_1, \ldots, u_r\right)$ ， $\mathcal{N}(Q)=\operatorname{span}\left(v_{r+1}, \ldots, v_n\right)$ 这里$r$表示投影矩阵的秩，请据此写出$Q$的特征分解 $Q=X D X^{-1}$的具体形式。
		\item [(4)] 证明：当 $Q \neq I_n$， $\operatorname{det}(Q)=0$。
	\end{itemize}
	
\end{exercise}
\begin{Solution}
(1)
$\forall \ y \in \mathcal{R}(Q)$必存在$x \in \mathbb{R}^n$，使得$y=Q x$ 成立。因此，$Q y=Q^2 x=Q x=y$。另外，
$\forall x \in \mathbb{R}^n$，$Q(Q x-x)=Q^2 x-Q x=Q x-Q x=0$。
\hfill \textcolor{red}{\textbf{（3分）}}

(2)
对 $\lambda \in \Lambda(Q)$，$x \in \mathbb{R}^n \backslash\{0\}$，有 $Q x=\lambda x$. 由于 $Q=Q^2$,  $\lambda x=Q x=Q(Q x)=Q(\lambda x)=\lambda Q x=\lambda^2 x$。因为 $x \neq 0 \in \mathbb{R}^n$，故 $\lambda=\lambda^2$，$\lambda \in\{0, 1\}$。因此 $\Lambda(Q) \subseteq\{0,1\}$.	\hfill \textcolor{red}{\textbf{（3分）}}

(3)
由(1)可知，$\forall i = 1,...,r, u_i\in \mathcal{R}(Q), Q u_i=u_i$，以及$\forall j = r+1,...,n,v_j\in \mathcal{N}(Q),Q v_j=0$。
故令 $$X:=\left(u_1|\cdots| u_r\left|v_{r+1}\right| \cdots \mid v_n\right) \in \mathbb{R}^{n \times n},$$ $$D:=\operatorname{diag}_{n \times n}(\underbrace{1, \ldots, 1}_{r \text { times }}, 0 \ldots, 0) \in \mathbb{R}^{n \times n},$$
此时$Q=X D X^{-1}$。
\hfill \textcolor{red}{\textbf{（4分）}}

(3) 反证$\operatorname{det}(Q) \neq 0 \Longrightarrow Q=I_n$。由于 $\operatorname{det}(Q) \neq 0$，故$Q$ 可逆。故由 $Q^2=Q$，得 $Q^{-1} Q^2=Q^{-1} Q$，即$Q=I_n$。 \hfill \textcolor{red}{\textbf{（3分）}}
	
\end{Solution}

\begin{exercise}(12')
	已知矩阵\[ \MM = \begin{pmatrix}
		0&-3&3\\0&0&4\\2&1&1
	\end{pmatrix}
	\]
	
	\begin{itemize}
		\item [(1)] 先求矩阵$\MM$的QR分解，然后根据QR分解求解方程组$\MM \Vx = \Vb$，其中$\Vb=[6, 4, 1]^\top$；
		\item [(2)] 请根据你对LU分解、Cholesky分解和QR分解的理解，谈谈它们之间的联系与差异。
	\end{itemize}
	
\end{exercise}
\begin{Solution}
	（1）因为 $\boldsymbol{\alpha}_1=(0,0,2)^T$, 记 $a_1=\left\|\alpha_1\right\|_2=2$, 令 $\quad \boldsymbol{w}_1=\frac{\alpha_1-a_1 e_1}{\left\|\alpha_1-a_1 e_1\right\|_2}=$ $\frac{1}{\sqrt{2}}(-1,0,1)^T$, 则
	$$
	\boldsymbol{H}_1=I-2 \boldsymbol{w}_1 \boldsymbol{w}_1^H=\left(\begin{array}{ccc}
		0 & 0 & 1 \\
		0 & 1 & 0 \\
		1 & 0 & 0
	\end{array}\right)
	$$
	从而
	$$
	\boldsymbol{H}_1 \boldsymbol{M}=\left(\begin{array}{ccc}
		2 & 1 & 1 \\
		0 & 0 & 4 \\
		0 & -3 & 3
	\end{array}\right)
	$$
	记 $\boldsymbol{\beta}=(0,-3)^T$, 则 $b_2=\left\|\boldsymbol{\beta}_2\right\|_2=3$, 令 $\boldsymbol{w}_2=\frac{\boldsymbol{\beta}_2-b_2 e_1}{\left\|\boldsymbol{\beta}_2-b_2 \boldsymbol{e}_1\right\|_2}=\frac{1}{\sqrt{2}}(-1,-1)^T$
	$$
	\widetilde{\boldsymbol{H}}_2=\boldsymbol{I}-2 \boldsymbol{w}_2 \boldsymbol{w}_2^{\boldsymbol{H}}=\left(\begin{array}{cc}
		0 & -1 \\
		-1 & 0
	\end{array}\right)
	$$
	记
	$$
	\boldsymbol{H}_2=\left(\begin{array}{cc}
		1 & 0^T \\
		0 & \widetilde{\boldsymbol{H}}_2
	\end{array}\right)=\left(\begin{array}{ccc}
		1 & 0 & 0 \\
		0 & 0 & -1 \\
		0 & -1 & 0
	\end{array}\right)
	$$
	则
	$$
	\boldsymbol{H}_2\left(\boldsymbol{H}_1 \boldsymbol{M}\right)=\left(\begin{array}{ccc}
		2 & 1 & 1 \\
		0 & 3 & -3 \\
		0 & 0 & -4
	\end{array}\right)=\boldsymbol{R}
	$$
	易知 $\mathrm{Rx}=H_2 H_1 b=(1,-6,-4)^T$, 故可求得
	$
	\mathrm{x}=(1 / 2, \quad-1, \quad 1)^T
	$ \hfill \textcolor{red}{\textbf{（7分）}}
	
	（2）（总体上，只要理解正确即可）这三种分解方式的联系在于将一个非三角矩阵转化为三角矩阵，这样便可以有效提高实际应用中一系列方程组求解的效率。它们区别在于LU分解和Cholesky分解是基于高斯消去法，分别适用于一般地可逆矩阵和对称矩阵，QR分解则是利用正交投影的方法，将向量分别投影到左边平面上的方式，从而达到对角化。 \hfill \textcolor{red}{\textbf{（5分）}}
\end{Solution}


\begin{exercise}(12')
	完成下列矩阵函数求梯度：
	\begin{itemize}
		\item [(1)] 求行列式函数$f(\MX)=|\MX^3|$的梯度矩阵，其中变量$\MX \in \NR^{n\times n} $非奇异；
		\item [(2)] 求迹函数$f(\MX) = Tr(\MX^\top\MX^{-1}\MA)$的梯度矩阵，其中变量$\MX \in \NR^{n\times n} $非奇异。
	\end{itemize}
\end{exercise}
\begin{Solution}
	（1）因为$d|\MX| =Tr(|\MX|\MX^{-1}d\MX)$，因此
	$$
	\begin{aligned}
		d(|\MX^{3}|)&= Tr( \MX \MX^{-3} d\MX^{3})\\
		&=Tr(|\MX^3| X^{-3} (d\MX \cdot \MX^2+\MX d\MX \cdot \MX + \MX^2d\MX))\\
		&=Tr(3|\MX|^3 \MX^{-1} d\MX)
	\end{aligned}
	$$
	所以梯度矩阵$3|\MX|^3 (\MX^{-1})^\top$。
	\hfill \textcolor{red}{\textbf{（6分）}}
	
	（2）
	
	$$
	\begin{aligned}
		dTr(\MX^\top \MX^{-1} \MA) &= Tr(d(\MX^\top \MX^{-1} \MA))\\
		&= Tr( d\MX^\top \MX^{-1}\MA -\MX^\top \MX^{-1} d\MX \MX^{-1} \MA)\\
		&= Tr((\MA^\top (\MX^{-1})^\top -\MX^{-1}\MA\MX^\top \MX^{-1}) d\MX)
	\end{aligned}
	$$
	
	即
	
	$$
	\begin{aligned}
		\frac{\partial Tr(\MX^\top \MX^{-1} \MA)}{\partial \MX} = (\MA^\top (\MX^{-1})^\top -\MX^{-1}\MA\MX^\top \MX^{-1})^\top
	\end{aligned}
	$$\hfill \textcolor{red}{\textbf{（6分）}}
	
\end{Solution}


\begin{exercise}(13')
	矩阵\[ \MA = \begin{pmatrix}
		7/5&-1/5\\
		1/5&7/5\\
		0&0
	\end{pmatrix}
 \]
 \begin{itemize}
 	\item [(1)] 计算矩阵$ \MA $的SVD分解；
 	\item [(2)] 假设$\MM$是任意一个非奇异$n \times d$的矩阵，已知其奇异值分解为$\MM = \MU \Sigma \MV^\top$，其中$\MU = [u_1, u_2, \cdots, u_n]$，$\Sigma = \diag(\lambda_1, \lambda_2, \cdots, \lambda_n)$，$\MV = [v_1, v_2, \cdots, v_n]$。请分别写出矩阵$\MM$的逆矩阵的SVD分解；
 	\item [(3)] 请写出(2)中$\MM$的转置矩阵的SVD分解。
 \end{itemize}
\end{exercise}
\begin{Solution}
	（1）易计算
			$$\MA^\top \MA =\begin{pmatrix}
				2& 0\\
				0& 2\end{pmatrix}$$
		求得其特征值为$2,9$。对应的特征向量分别为$(1, 0)^\top, (0, 1)^\top$，因此，
		$$\MV =\begin{pmatrix}
			1& 0\\
			0& 1\end{pmatrix}$$\hfill \textcolor{red}{\textbf{（3分）}}
		
		由$\MA \MV$与$\MU$的关系可直接计算出
		$$\MU =\begin{pmatrix}
			7/5\sqrt{2}& -1/5\sqrt{2}& 0\\
			1/5\sqrt{2}& 7/5\sqrt{2} & 0\\
			0& 0 & 1
	\end{pmatrix}$$\hfill \textcolor{red}{\textbf{（3分）}}

	（2）因为$\MM$的SVD分解为
	$$
	\MM=U \Sigma V^{\mathrm{T}}=\left(u_1|\cdots| u_n\right)\left[\operatorname{diag}_{n \times n}\left(\lambda_1, \ldots, \lambda_n\right)\right]\left(v_1|\cdots| v_n\right)^{\mathrm{T}}
	$$
	其中 $U, V \in \mathbb{R}^{n \times n}$ 正交, $\lambda_1 \geq \lambda_2 \geq \cdots \geq \lambda_n \geq 0$。 因为$\MM$可逆，有 $\operatorname{rank}(\MM)=n$ , 故$\lambda_i>0$ , $\forall i \in\{1, \ldots, n\}$.又由 $\MM=U \Sigma V^{\mathrm{T}}$ 有 $\MM v_i=\lambda_i u_i$ $\forall i \in\{1, \ldots, n\}$ ，因此 
	$$\MM^{-1} u_i=\MM^{-1}\left(\frac{1}{\lambda_i} \MM v_i\right)=\frac{1}{\lambda_i} v_i$$
	其中 $\frac{1}{\lambda_n} \geq \cdots \geq \frac{1}{\lambda_2} \geq \frac{1}{\lambda_1}>0$。综上
	$$
	\MM^{-1}=\left(v_n|\cdots| v_2 \mid v_1\right)\left[\operatorname{diag}_{n \times n}\left(\frac{1}{\lambda_n}, \ldots, \frac{1}{\lambda_2}, \frac{1}{\lambda_1}\right)\right]\left(u_n|\cdots| u_2 \mid u_1\right)^{\mathrm{T}},
	$$
	整理可得
	$$
	\MM^{-1}=(V P)\left(P \Sigma^{-1} P\right)(U P)^{\mathrm{T}}.
	$$
	记 $P:=\left(e_n|\cdots| e_2 \mid e_1\right) \in \mathbb{R}^{n \times n}$. (由于 $P P^{\mathrm{T}}=P^2=I_n$， $P$是正交阵， 且$V P$, $U P$ 是正交阵)。\hfill \textcolor{red}{\textbf{（5分）}}
	
	（3）因为$\MM$的SVD分解为
	$$
	\MM=U \Sigma V^{\mathrm{T}}
	$$
	其中 $U, V \in \mathbb{R}^{n \times n}$ 正交。 
	易得
	$$
	\MM^\top=V \Sigma U^T.
	$$
	显然$V$, $U$ 是正交阵。\hfill \textcolor{red}{\textbf{（2分）}}
\end{Solution}


\begin{exercise}(13')
	已知矩阵\[ \MM = \begin{pmatrix}
		2&0\\
		-1&2\\
		0&3\\
	\end{pmatrix}
	\]
	\begin{itemize}
		\item [(1)] 计算矩阵 $\MM$ 的 $1$ 范数和$\infty$范数；
		\item [(2)] 计算矩阵 $\MM$ 的 $F$ 范数和$2$范数。
		\item [(3)] 试比较任意矩阵$\MA$的 $F$ 范数和$2$范数的大小，并给出理由。
	\end{itemize}
\end{exercise}
\begin{Solution}
	（1）	
	$$\|\MM\|_1=\max\{2+\|-1\|,0+2+3\}=5$$ 
	$$\|\MM\|_{\infty}=\max\{2+\|0\|,\|-1\|+2, 0+3\}=3$$
	\hfill \textcolor{red}{\textbf{（4分）}}
	
	（2）$\MM^\top \MM=\begin{pmatrix}5&-2\\-2&13\end{pmatrix}$
	
	$\lambda_{max}(\MM^\top \MM)=9+2\sqrt{2}$
	
	$\|\MM\|_2=\sqrt{9+2\sqrt{2}}$ 
	
	易求得
	$\|\MM\|_F=\sqrt{18}=3\sqrt{2}$ 
	\hfill \textcolor{red}{\textbf{（5分）}}
	
	（3）显然$F$范数大于$2$范数，因为$F$范数的平方是所有奇异值的平方之和，而$2$范数的平方是最大奇异值的平方，因此可知这一点成立。 \hfill \textcolor{red}{\textbf{（4分）}}
\end{Solution}


\begin{exercise}(12')
	求解以下问题：
\begin{itemize}
	\item [(1)] 证明: Gauss概率密度函数的累积分布函数
	\begin{displaymath}
		\Phi(x)=\frac{1}{\sqrt{2\pi}}\int^{x}_{-\infty}e^{-u^{2}/2}du
	\end{displaymath}
	是对数-凹函数. 即$ \log(\Phi(x)) $是凹函数。
	\item [(2)] 设总体 $X \sim E(\theta), X_{1}, X_{2}, \ldots, X_{n}$ 为来自总体 $X$ 的样本, $\theta$ 的先验分布
	为指数分布 $E(\lambda)$ ( $\lambda$ 已知), 求 $\theta$ 的最大后验估计。
\end{itemize}

\end{exercise}
\begin{Solution}
	（1）由题意得,
	$$\Phi(x)=\frac{1}{\sqrt{2\pi}}\int^{x}_{-\infty}e^{-u^{2}/2}du $$
	$$\Phi^{'}(x)=\frac{1}{\sqrt{2\pi}}e^{-x^{2}/2}$$
	$$\Phi^{''}(x)=\frac{1}{\sqrt{2\pi}}e^{-x^{2}/2}(-x)$$
	$$(\Phi^{'}(x))^{2}=\frac{1}{2\pi}e^{-x^{2}}$$
	$$\Phi(x)\log\Phi^{''}(x) = \frac{1}{2\pi}\int^{x}_{-\infty}e^{-u^{2}/2}du \cdot e^{-x^{2}/2}(-x)$$
	\hfill \textcolor{red}{\textbf{（3分）}}
	
	当$x\geq 0$时, $(\Phi^{'}(x))^{2} \geq 0 \geq \Phi(x)\Phi^{''}(x)$. \\
	当$x < 0$时, 由于$\frac{u^{2}}{2}$是凸函数, 则
	$$\frac{u^{2}}{2} \geq \frac{x^{2}}{2} + (u-x)x\geq xu - \frac{x^{2}}{2}$$
	所以,
	$$\int^{x}_{-\infty}e^{-u^{2}/2}du \leq  \int^{x}_{-\infty}e^{\frac{x^{2}}{2}- xu}du$$
	$$=  e^{\frac{x^{2}}{2}\cdot\frac{e^{-xu}}{-x}\big|_{u=-\infty}^{x}}$$
	$$=  e^{\frac{x^{2}}{2}}\cdot\frac{e^{-x^{2}}}{-x}$$
	因此$\Phi(x)\Phi^{''}(x) \leq \frac{1}{2\pi}e^{-x^{2}} = (\Phi^{'}(x))^{2}$, $\Phi(x)$是对数凹函数.
	\hfill \textcolor{red}{\textbf{（3分）}}
	
	（2）因为先验概率密度函数为:
	$$
	\pi(\theta)=\left\{\begin{array}{cc}
		\lambda e^{-\lambda \theta} & \theta>0 \\
		0 & \theta \leq 0
	\end{array}\right.
	$$
	样本 $\left(X_{1}, X_{2}, \ldots, X_{n}\right)$ 的联合概率密度为:
	$$
	q(\mathbf{x} \mid \theta)=\prod_{n=2}^{n} f\left(x_{i} \mid \theta\right)=\left\{\begin{array}{cc}
		\theta^{n} e^{-\theta \sum_{i=1}^{n} x_{i}} & x_{1}, x_{2}, \ldots, x_{n}>0 \\
		0 & \text { 其它 }
	\end{array}\right.
	$$
	所以 $\theta$ 的后验分布密度
	$$
	\begin{gathered}
		h(\theta \mid \mathbf{x}) \propto \theta^{n} e^{-\left(\lambda+\sum_{i=1}^{n} x_{i}\right) \theta} \\
		\ln h(\theta \mid \mathbf{x})=n \ln \theta-\left(\lambda+\sum_{i=1}^{n} x_{i}\right) \theta+\ln c(\mathbf{x}) \\
		\frac{\partial \ln h(\theta \mid \mathbf{x})}{\partial \theta}=\frac{n}{\theta}-\left(\lambda+\sum_{i=1}^{n} x_{i}\right)=0
	\end{gathered}
	$$
	求得 $\theta$ 的最大后验估计为 $\hat{\theta}=\frac{1}{\bar{x}+\lambda / n}$ 。当 $n \rightarrow \infty$ 时, $\hat{\theta} \rightarrow \frac{1}{\bar{x}}$, 与传统意义下的极 大似然估计是一致的。\hfill \textcolor{red}{\textbf{（6分）}}
\end{Solution}




\begin{exercise}(13')
	求解下述问题：
	\begin{itemize}
		\item[(1)] 写出下述非线性规划的KKT条件，并求解
		\begin{align*}
			\quad \texttt{maximize} \quad & f(x)=(x-4)^2 \\
			\texttt{suject to} \quad & 1\leq x \leq 5 
		\end{align*}
		\item [(2)] 用Lagrange乘子法证明：矩阵$ \MA\in\NR^{m\times n} $的2范数 \[ \Vert\MA\Vert_{2}=\max_{\Vert\Vx\Vert_2=1,\Vx\in\NR^n}\Vert\MA\Vx\Vert_{2} \] 的平方是$ \MA\T\MA $的最大特征值。
	\end{itemize}
\end{exercise}
\begin{Solution}
	（1）原问题等价于
	\begin{equation*}
		\left\{
		\begin{aligned}
			& \texttt{minimize}  \quad - f(x)=(x-4)^2\\
			& g_{1}(x) = -x + 1 \leq 5\\
			& g_{2}(x) = x - 5 \leq 0 \\
		\end{aligned}
		\right.
	\end{equation*}
	求目标函数和约束函数的梯度得,
	$$\nabla_{x}f(x) = -2(x-4), \nabla_{x}g_{1}(x) = -1, \nabla_{x}g_{2}(x) = 1$$
	将约束引入广义Lagrange乘子$v_{1}, v_{2}$, 在KKT条件上有
	\begin{equation*}
		\left\{
		\begin{aligned}
			& -2(x^{*} - 4) - v_{1}^{*} + v_{2}^{*} = 0\\
			& v_{1}^{*}(-x^{*} + 1) = 0\\
			& v_{2}^{*}(x^{*} - 5) = 0 \\
			& v_{1}^{*} \geq 0, v_{2}^{*}\geq 0
		\end{aligned}
		\right.
	\end{equation*}
\hfill \textcolor{red}{\textbf{（4分）}}

	若$v_{1}^{*}\neq 0, v_{2}^{*}\neq 0$, 无解. \\
	若$v_{1}^{*} = 0, v_{2}^{*}\neq 0$, 得$x^{*} = 5, v_{2}^{*} = 2, -f(x^{*}) = -1$. \\
	若$v_{1}^{*} \neq 0, v_{2}^{*}= 0$, 得$x^{*} = 1, v_{1}^{*} = 6, -f(x^{*}) = -9$. \\
	若$v_{1}^{*} = 0, v_{2}^{*}= 0$, 得$x^{*} = 4, f(x^{*}) = 0$. \\
	因此最优点$x^{*} = 1$, $\texttt{maximize}f(x) = 9$。
	\hfill \textcolor{red}{\textbf{（3分）}}
	
	（2）优化问题为\[ 	\begin{aligned}
		\texttt{maximize} \quad & f(\Vx)=\Vx\T\MA\T\MA\Vx \\
		\texttt{suject to} \quad & \Vx\T\Vx=1
	\end{aligned} \]
	Lagrange函数为：
	\[ L(\Vx)=\Vx\T\MA\T\MA\Vx-\lambda(\Vx\T\Vx-1) \]
	\[ \frac{\partial L}{\partial \Vx}= 2\MA\T\MA\Vx -2\lambda\Vx\]
	令$ \frac{\partial L}{\partial \Vx}=0 $，有：
	\[ \MA\T\MA\Vx =\lambda \]
	\hfill \textcolor{red}{\textbf{（3分）}}
	
	这表示在$ f(\Vx) $的极大值点，$ \Vx $是$ \MA\T\MA $的特征向量，$ \lambda $是对应的特征值。此时，\[  f(\Vx)=\Vx\T\MA\T\MA\Vx=\Vx\T\lambda\Vx=\lambda\Vx\T\Vx=\lambda  \]
	因此说明，为使$ f(\Vx) $最大，$ f(\Vx)=\lambda_{max}(\MA\T\MA) $，其中$ \lambda_{max} $表示最大特征值。即
	\[ \Vert\MA\Vert_{2}^2=\lambda_{max}(\MA\T\MA) \]
	\hfill \textcolor{red}{\textbf{（3分）}}
\end{Solution}

\begin{exercise}(12')
	求解如下优化问题
	\begin{itemize}
		\item [(1)] 考虑问题
		$$
		\min f(\Vx)=3 x_1^2+3 x_2^2-2x_1^2 x_2 .
		$$
		从初始点$\Vx^{(0)}=(0,1)^{\mathrm{T}}$出发, 写出用 最速下降法迭代两步的求解过程，并说明迭代是否可以终止。
		\item[(2)] 尽管牛顿法在求解无约束优化问题时，具有更高阶的收敛速度，但在处理大规模问题时，该方法涉及的Hessian矩阵及其逆矩阵的计算是非常耗时的。因此，研究者们探究了对Hessian矩阵逆近似的迭代方法，也就是拟牛顿法或变尺度法。通常这样近似Hessian矩阵或逆矩阵需要保持原有的性质，即满足割线方程:
		$$\Delta x^{(k)} = \bar{H}^{(k+1)} \Delta g^{(k)},$$
		其中$\bar{H}^{(k)}$表示矩阵的Hessian矩阵逆的近似。如果已经得到上一轮迭代时的近似$\bar{H}^{(k)}$，则一般地做法是通过秩一修正或秩二修正得到下一轮的近似矩阵$\bar{H}^{(k+1)}$。当采用秩二修正时，便得到著名的DFP法。现已知第$k$次迭代时的$\Delta x^{(k)}, \bar{H}^{(k)}, \Delta g^{(k)}$，请给出下一轮迭代的Hessian矩阵逆的近似的推导过程。
	\end{itemize}
\end{exercise}

\begin{Solution}
	（1）由题意得, $\nabla_{\Vx}f(\Vx) = (6x_1-4x_1x_2, 6x_2-2x_1^2)^T$，故$g^{(0)}=\nabla_{\Vx}f(\Vx^{(0)})=(0, 6)$。现设最速下降法的步长为$\lambda$, 那么
	\begin{align*}
		f(\Vx^{(0)} - \lambda g^{(0)}) = 3(1-6\lambda^2)
	\end{align*}
	在$\nabla_{\Vx} f(\Vx^{(0)})$方向上, 使$f(\Vx)$最小的$\lambda$为
	$$\lambda = \frac{1}{6}$$
	所以,
	$$\Vx^{(1)} = \Vx^{(0)} - \frac{1}{2}\nabla_{\Vx}f(\Vx^{(0)}) = (0, 0)^{T}$$
	易知此时$\Vx^{(1)}$处的梯度已经为0，可见已经收敛。显然
	$$\Vx^{(2)} = (0, 0)^{T}$$
	\hfill \textcolor{red}{\textbf{（7分）}}
	
	（2）可设
	\begin{equation*}
		\overline{\MH}^{(k+1)}=\overline{\MH}^{(k)}+a\Vu\Vu^T+b\Vv\Vv^T
	\end{equation*}
	其中$\Vu,\Vv\in\NR^n,~a,b\in\NR$待定。
	
	同上所述，仍然利用割线方程，有
	\begin{equation*}
		\begin{aligned}
			\Delta\Vx^{(k)}
			& =\overline{\MH}^{(k+1)} \Delta\Vg^{(k)} \\
			& = (\overline{\MH}^{(k)}+a\Vu\Vu^T+b\Vv\Vv^T) \Delta\Vg^{(k)} \\
		\end{aligned}
	\end{equation*}
	整理得
	\[ a(\Vu^T \Delta\Vg^{(k)})\Vu + b(\Vv^T \Delta\Vg^{(k)})\Vv = \Delta\Vx^{(k)} - \overline{\MH}^{(k)} \Delta\Vg^{(k)}. \]
	因此，$\Vu,\Vv$的线性组合等于$\Delta\Vx^{(k)} - \overline{\MH}^{(k)} \Delta\Vg^{(k)}$。同样地，不妨令$\Vu = \Delta\Vx^{(k)}$，$\Vv = \overline{\MH}^{(k)} \Delta\Vg^{(k)}$，则代入可得
	\[ a = \frac{1}{(\Delta\Vx^{(k)})^T \Delta\Vg^{(k)}}, \]
	\[ b = -\frac{1}{(\Delta\Vg^{(k)})^T \overline{\MH}^{(k)} \Delta\Vg^{(k)}}. \]
	从而，得到更新公式：
	\begin{equation*}\label{eq_dfp}
		\overline{\MH}^{(k+1)}=\overline{\MH}^{(k)} + \frac{\Delta\Vx^{(k)}) \Delta\Vx^{(k)})^T}{(\Delta\Vx^{(k)})^T \Delta\Vg^{(k)}} - \frac{\overline{\MH}^{(k)} \Delta\Vg^{(k)} (\overline{\MH}^{(k)} \Delta\Vg^{(k)})^T}{(\Delta\Vg^{(k)})^T \overline{\MH}^{(k)} \Delta\Vg^{(k)}} .
	\end{equation*}
	\hfill \textcolor{red}{\textbf{（5分）}}
\end{Solution}




\end{document}

