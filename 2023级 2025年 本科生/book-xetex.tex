\documentclass[12pt,a4paper,openany,twoside]{ctexbook}
\input{setup/package.tex}   %引用宏包所在位置
\input{setup/format.tex}    %格式所在位置
\input{setup/math_symbol}
\input{setup/refer}

\newcommand{\underbox}[2]{\kern0pt\underline{\makebox[#1]{#2}}\kern0pt\relax}
\newcommand{\purespace}[1]{\kern0pt {\hspace{#1}}\kern0pt\relax}

\begin{document}

\setcounter{chapter}{1}
\chapter*{华东师范大学期末试卷 (A 卷)}
\vspace{-1cm}
\section*{2024—2025学年第一学期}

\begin{center}
	考试科目：\underbox{11\ccwd}{数据科学与工程数学基础} \quad 任课教师：\underbox{6\ccwd}{树扬} \\
	姓\purespace{2\ccwd}名：\underbox{11\ccwd}{} \quad 学\purespace{2\ccwd}号：\underbox{6\ccwd}{} \\
	专\purespace{2\ccwd}业：\underbox{11\ccwd}{} \quad 班\purespace{2\ccwd}级：\underbox{6\ccwd}{}\\
\end{center}
{ \begin{center}
		\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|}
			\hline 
			题目 & 一（选择题） & 二 & 三 & 四 & 五 & 六 & 总分 &阅卷人签名 \\ 
			\hline 
			得分 &  &  &  &  &  &  &  &  \\ 
			\hline 
		\end{tabular} 
		
\end{center}}

\begin{exercise}(20分)
	选择题\\
	单选题一道3分，多选题一道5分，总计20分。
	单选题不选、错选均不得分；多选题不选、错选不得分，少选得3分。

	\begin{itemize}
		\item [(1)]  若 $\MA=[\mathbf{a_1},\mathbf{a_2},...,\mathbf{a_n}]\in {\mathbb{R}}^{m \times n}$ ，列空间为 $Col(\MA)$，行空间为 $Col(\MA^T)$，零空间为 $Null(\MA)$，左零空间为  $Null(\MA^T)$。下列说法错误的是（ \quad ）
		\begin{itemize}
			\item [(A)]  $Col(\MA^T)$ $\perp$ $Null(\MA)$，$Col(\MA) $ $\perp$ $Null(\MA^T )$
			\item [(B)] $dim(Col(\MA^T))=dim(Col(\MA))=rank(\MA)$
			\item [(C)] 若 $\mathbf{x}\in {\mathbb{R}}^{m}$ 在 $Col(\MA)$ 上的正交投影为 $\pi(\mathbf{x})$，则对 $\forall i=1,...,n$ 有$\mathbf{a_i^T}(\mathbf{x}-\pi(\mathbf{x}))=0$
			\item [(D)] $dim(Null(\MA^T))=n-rank(\MA)$，$dim(Null(\MA))=m-rank(\MA)$
		\end{itemize}

		\item [(2)] 已知矩阵$\MA=\begin{bmatrix}  
			1 & 0 & -1\\  
			 -1 & 2 & 0 \\  
			\end{bmatrix}$，$(\MA\MA^T)^{-1}=\begin{bmatrix}  
			5/9 & 1/9\\  
			1/9 & 2/9\\  
			\end{bmatrix}$，则矩阵 $\MA$ 的广义逆是（\quad）

			\begin{itemize}
				\begin{minipage}[t]{0.3\textwidth}
					\item[(A)] $\begin{bmatrix}  
						2/3 & -1/9\\  
						1/3 & 4/9 \\ 
						-1/3 & -1/9 \\  
						\end{bmatrix}$
					\item[(C)] $\begin{bmatrix}  
						4/9 & -1/3\\  
						2/9 & 1/3 \\ 
						-5/9 & -1/3 \\  
						\end{bmatrix}$
				\end{minipage}
				\hfill
				\begin{minipage}[t]{0.3\textwidth}
					\item[(B)] $\begin{bmatrix}  
						4/9 & -1/9\\  
						2/9 & 4/9 \\ 
						-5/9 & -1/9 \\  
						\end{bmatrix}$
					\item[(D)] $\begin{bmatrix}  
						4/9 & -1/9\\  
						2/9 & 4/9 \\ 
						-5/9 & 1/9 \\  
						\end{bmatrix}$
				\end{minipage}
				\hfill
			\end{itemize}


		\item [(3)] 下面的集合不是凸集的是（\quad）
		\begin{itemize}
			\item [(A)] 一条射线，即 $\{\mathbf{x_0}+\theta\mathbf{v}\ |\  \theta \geq0 ,\mathbf{v} \not= \mathbf{0}\}$
			\item [(B)] 若$0<r_1 < r_2$，$\{(x, y) \mid r_1^2 \leq (x - x_0)^2 + (y - y_0)^2 \leq r_2^2\}$
			\item [(C)] 设$||·||$是$\mathbb{R}^{n}$中的范数，$r>0$，$\{\mathbf{x}\ | \space\ ||\mathbf{x}-\mathbf{x_0}||\leq r \}$
			\item [(D)] 多面体$\{ \mathbf{x}| \space \mathbf{Ax}\leq\mathbf{b}, \mathbf{Cx}=\mathbf{d}\}$.其中$\mathbf{A}\in\mathbb{R}^{m \times n}, \mathbf{C} \in\mathbb{R}^{p \times n},\mathbf{x}\in\mathbb{R}^{n},\mathbf{b}\in\mathbb{R}^{m},\mathbf{d}\in\mathbb{R}^{p}$，$\mathbf{x}\leq\mathbf{y}$表示向量$\mathbf{x}$的每个分量均小于等于$\mathbf{y}$的对应分量。
		\end{itemize}

		\item [(4)] 下列关于向量范数说法错误的是（\quad）
		\begin{itemize}
			\item [(A)] 设 $\Vu$ 为 $n$ 维单位列向量，$I_n$ 为$n$维单位矩阵，$\MA=I_n-2\Vu\Vu^T$。若$\MA\Vx=\Vy$，则$||\Vx||_{2}=||\Vy||_{2}$
			\item [(B)] 若 $\Vx\in {\mathbb{R}}^n$，则 $||\Vx||_{2}\leq||\Vx||_{1}\leq n||\Vx||_{\infty}$
			\item [(C)] 若 $\Vx\in {\mathbb{R}}^n$，$p>0$，则 $(\sum_{i=1}^{n} x_i^p)^{\frac{1}{p}}$ 是向量的$l_p$范数
			\item [(D)] $\MP=(\Vp_1,\Vp_2,...,\Vp_n)\in \mathbb{R}^{n \times n}$为非奇异矩阵，则对于 $\forall \Vx\in {\mathbb{R}}^n$，$||\MP\Vx||_1 \leq \underset {1 \leq j \leq n}{max} ||\Vp_j||_1 · ||\Vx||_1$
		\end{itemize}

		\item [(5)] 考虑一个线性映射$\Phi: \mathbb{R}^2 \to \mathbb{R}^3 $，其在标准基（基矩阵为单位阵）下的变换矩阵为：$\begin{bmatrix}
			1 & 2 \\
			-1 & 3 \\
			4 & 2  \\
			\end{bmatrix}$
			我们寻找一组新的基下的 $\Phi$ 的变换矩阵。令新的基分别为：

			$$
			\tilde{\MB} = 
			\left(
			\begin{bmatrix}
			1 \\ 1 
			\end{bmatrix},
			\begin{bmatrix}
			0 \\ 1
			\end{bmatrix}
			\right),
			\tilde{\MC} = 
			\left(
			\begin{bmatrix}
			1 \\ 1 \\ 0
			\end{bmatrix},
			\begin{bmatrix}
			1 \\ 0 \\ 1 
			\end{bmatrix},
			\begin{bmatrix}
			0 \\ 1 \\ 1
			\end{bmatrix}
			\right)
			$$
			
			通过计算可得：
			$$
		 {\tilde{\MB}^{-1}} = 
			\begin{pmatrix}
			1 & 0  \\
			-1 & 1 \\
			\end{pmatrix},
			\quad
			{\tilde{\MC}^{-1}} = 
			\frac{1}{2}
			\begin{pmatrix}
			1 & 1 & -1 \\
			1 & -1 & 1 \\
			-1 & 1 & 1 \\
			\end{pmatrix}
			$$
			
			请问下面哪项为新的基下的变换矩阵（ \quad）	
		$$
		(A)\  \frac{1}{2}
\begin{pmatrix}
-1 & 3 \\
7 & 1 \\
5 & 3 \\
\end{pmatrix}
\quad
(B) \begin{pmatrix}
-1 & 3 \\
7 & 1 \\
5 & 3 \\
\end{pmatrix}
\quad
(C) \begin{pmatrix}
-5 & 5 \\
1 & 4 \\
-2 & 5 \\
\end{pmatrix}
\quad
(D) \frac{1}{2}
\begin{pmatrix}
-7 & 3 \\
5 & 1 \\
-1 & 3 \\
\end{pmatrix}
		$$
\\
		\item [(6)] 【多选】设矩阵 $\MA\in \mathbb{R}^{m \times n}$，它的完全奇异值分解为$\MA=\MU \sum \MV^T$ ，紧奇异值分解为$\MA=\MU_r \sum_r \MV_r^T$，$r=rank(\MA)$，下列关于SVD(奇异值分解)的说法错误的是（\quad）
		
		
		\begin{itemize}
			\item [(A)] 对矩阵 $\MA$ 的奇异值分解中，$\MU,\MV$ 矩阵是唯一的
			\item [(B)] $rank(\MA)=rank(\MA^T\MA)=rank(\MA\MA^T)$
			\item [(C)] $\MA$ 的奇异值分解可以表示为：$\MA = \sum_{i=1}^r \sigma_i \Vu_i \Vv_i^\top$。在 $r \geq 2 $时，令 $\Vw \in \mathbb{R}^n $ 为一个向量且满足：$\Vw = \alpha \Vv_1 + \beta \Vv_2$，则$\MA\Vw=\alpha \sigma_1 \Vu_1+\beta \sigma_2 \Vu_2$
			\item [(D)] $\forall i=r+1,...m,j=1,...n$，$\Vu_i^T\MA\Vv_j\not=0$
			\item [(E)] 利用截断SVD方法，寻找秩为 $k$ （ $k<r$）的 矩阵$\MX\in \mathbb{R}^{m \times n}$ 使得 $||\MA-\MX||_F$ 最小。寻找得到的最优矩阵就是在紧奇异值分解中对 $\sum_r$ 任意地选择 $k$ 个奇异值 $\sigma_i$ 和其对应的 $\MU_r$、$\MV_r$ 中的向量 $\Vu_i,\Vv_i$，再将选择到的 $\sigma_i \Vu_i \Vv_i^\top$ 累加求和即可。
		\end{itemize}
	\end{itemize}
	
\end{exercise}

\begin{exercise}\quad(12分)
	完成以下问题：
	
	\begin{itemize}
		\item [(1)](4分) $A=\begin{bmatrix}  
			1 & 2 \\  
			4 & 5 \\
			0 & -3 
			\end{bmatrix}$ 分别求$A$的 $l_1$ 范数，$1$范数，$l_{\infty}$范数，$\infty$范数
		\item [(2)](5分) 求向量 $\mathbf{x}=\begin{bmatrix}  
			1  \\  
			2 \\
			3 
			\end{bmatrix}$ 在矩阵 $M=\begin{bmatrix}  
			1 & -1 \\  
			2 & 4 \\
			4 & 2 
			\end{bmatrix}$的列空间上的正交投影。

			【\ 已知： $(M^TM)^{-1}=\frac{1}{72}\begin{bmatrix}  
				7 & -5 \\  
				-5 & 7 \\ 
				\end{bmatrix} $\ 】

		\item [(3)](3分) 设$\mathbf{B} \in \mathbb{R}^{n \times n}$，$I$ 是 n 阶单位矩阵，$||\mathbf{B}||$ 是关于 $\mathbf{B}$ 的矩阵 $l_2$ 范数。已知 $||\mathbf{B}|| < 1$，$I-\mathbf{B}$ 可逆，证明：$(1-||\mathbf{B}||)·||(I-\mathbf{B})^{-1}|| \leq n$。

		【提示：$I=(I-\mathbf{B})^{-1}·(I-\mathbf{B})=(I-\mathbf{B})^{-1}-(I-\mathbf{B})^{-1}\mathbf{B}$，
		
		则$(I-\mathbf{B})^{-1}=I+(I-\mathbf{B})^{-1}\mathbf{B}$\ 】
	\end{itemize}
	
\end{exercise}

\begin{exercise}\quad(17分)
	$$
	\mathbf{A}=\begin{bmatrix}  
		1 & 1 \\  
		2 & 0 \\
		2 & 3 
		\end{bmatrix},\quad
		\mathbf{B}=\begin{bmatrix}  
		0 & 3 & 1 \\  
		0 & 4 & -2 \\
		2 & 1 & -1
		\end{bmatrix},\quad
		\mathbf{c}=\begin{bmatrix}  
		17 \\  
		6 \\
		1 
		\end{bmatrix},\quad
		\mathbf{d}=\begin{bmatrix}  
		1 \\  
		-2 \\
		4
		\end{bmatrix}
	$$
	\begin{itemize}
		\item [(1)](2分) 矩阵$\mathbf{A}$能否进行QR分解，为什么？直接写出结论及原因即可。
		\item [(2)](6分) 求矩阵$\mathbf{B}$的QR分解。
		\item [(3)](5分) 利用(2)中的分解结果来求解方程组 $\mathbf{Bx}= \mathbf{c}$
		\item [(4)](4分) 利用正规化方程组，求解 $\mathbf{A}$ 和 $\mathbf{d}$ 所对应的最小二乘问题 $\underset{\mathbf{x}}{min}||\mathbf{A}\mathbf{x}-\mathbf{d}||_2$​ 的全部解。【对正规化方程组的求解方法不限】
	\end{itemize}

\end{exercise}

\begin{exercise}\quad(15分)
	\begin{itemize}
		\item [(1)] (6分)给定矩阵$\mathbf{A}=\begin{bmatrix}  
			1 & 3 & 2 \\  
			-1 & 2 & 3 \\  
			4 & 2 & -2  
			\end{bmatrix}  $，分别求其完全SVD和紧SVD。\\
			【已知： $\mathbf{A^T A}=\begin{bmatrix}  
			18 & 9 & -9 \\  
			9 & 17 & 8 \\  
			-9 & 8 & 17  
			\end{bmatrix}  $ ，$\mathbf{A^T A}$ 的特征值 $\lambda_1=27,\lambda_2=25,\lambda_3=0$，
			特征向量为$\Vq_1=\begin{bmatrix}  
			-2 & -1 & 1 
			\end{bmatrix}^T,\Vq_2=\begin{bmatrix}  
			0 & 1 & 1 
			\end{bmatrix}^T,\Vq_3=\begin{bmatrix}  
			-1 & 1 & -1 
			\end{bmatrix}^T$】
		\item [(2)] (4分)假设$\MM$是任意一个非奇异$n \times n$的矩阵，已知其奇异值分解（SVD）为$\MM = \MU \Sigma \MV^\top$，其中$\MU = [\Vu_1, \Vu_2, \cdots, \Vu_n]$，$\Sigma = \diag(\sigma_1, \sigma_2, \cdots, \sigma_n)$，$\MV = [\Vv_1, \Vv_2, \cdots, \Vv_n]$。请写出$\MM$的逆矩阵的SVD分解。
		\item [(3)] (5分)已知矩阵 $\MM \in \mathbb{R}^{m \times n} $ 的元素非负，$r=rank(\MM)$，其奇异值分解为 $\MM = \MU \Sigma \MV^\top$ ，其中$\MU = [\Vu_1, \Vu_2, \cdots, \Vu_r]$，$\Sigma = \diag(\sigma_1, \sigma_2, \cdots, \sigma_r)$，$\MV = [\Vv_1, \Vv_2, \cdots, \Vv_r]$。求拼接矩阵$\MA=\begin{bmatrix}  
			O & \MM \\  
			{\MM}^T & O 
			\end{bmatrix}$的非零特征值和其对应的特征向量。【结果用 $\Vu_i,\Vv_i,\sigma_i$ 相关形式表示】
	\end{itemize} 
\end{exercise}

\begin{exercise}\quad(19分)
	\begin{itemize}
		\item [(1)](2分)已知$\mathbf{X} \in \mathbb{R}^{n \times n}$非奇异，求证： $d(\mathbf{X}^{-1})=-\mathbf{X}^{-1}d\mathbf{X} \mathbf{X}^{-1}$。
		\item [(2)](5分)利用迹微分法求函数$f(\mathbf{X})=Tr(\mathbf{X}^{\top}\mathbf{X}^{-1}\mathbf{A})$关于变量$\mathbf{X}$的梯度矩阵，其中$\mathbf{X} \in \mathbb{R}^{n \times n}$非奇异，$\mathbf{A} \in \mathbb{R}^{n \times n}$是常数矩阵。
		\item [(3)](7分)考虑一个两层的全连接神经网络：
		\[
		\Vy=\Vf(\Vx)=\mathrm{ReLU}(\MA_2(\mathrm{ReLU}(\MA_1\Vx+\Vb_1))+\Vb_2)	
		\]
		$\mathrm{ReLU}$的含义：若$ \Vx=\begin{bmatrix}

			x_{1}  \\
			
			\vdots \\
			
			x_{n}
			
			\end{bmatrix} \in\mathbb{R}^{n}, \ \ 
			\text{则}\ \mathrm{ReLU}(\Vx)=\begin{bmatrix}
			
			\mathrm{ReLU}(x_{1}) \\
			
			\vdots \\
			
			\mathrm{ReLU}(x_{n})
			
			\end{bmatrix}$
		，其中\[
			\mathrm{ReLU}(x_{i})=\begin{cases}
				0, & \text {if $x_{i}\textless 0$ } \\
				x_{i}, & \text{if $x_{i}\geq 0$} \\
				\end{cases}
		\]
		已知：\[
		\MA_1=\begin{bmatrix}
			2&3\\
			-2&1\\
			3&-1
		\end{bmatrix}	,\MA_2=\begin{bmatrix}
			3&-1&0\\
			1&-2&2
		\end{bmatrix},\Vb_1=\begin{bmatrix}
			0\\0\\-3
		\end{bmatrix},\Vb_2=\begin{bmatrix}
			-7\\3
		\end{bmatrix}
		\]
		假设输入为$\Vx=(-1,2)^T$，并且对应的真实输出为$\hat{\Vy}=(0,1)^T$，采用平方损失$L=\frac12\|\Vy-\hat{\Vy}\|_2^2$。
		试计算函数$L$关于$\Vb_1$的梯度。


		\begin{figure}[htbp]
			\centering
			\includegraphics[scale=0.2]{conv.png}
			\label{figure}
		\end{figure}
		\item [(4)](5分)卷积是常用的数学运算，运算过程中，卷积核矩阵$\mathbf{F}$在输入矩阵$\mathbf{X}$上滑动，卷积核每滑动到与输入矩阵的某一子矩阵重叠时，卷积核与该子矩阵对应位置元素相乘再累加，得到输出结果在该位置的值。以步长（每次滑动的距离）等于1为例，其得到输出矩阵$\mathbf{O}$的过程和公式如图所示。
		


		已知，输入$\mathbf{X}=\begin{bmatrix}  
			3 & 1 & 2 \\  
			7 & 2 & 3 \\  
			4 & 5 & 6 \\
			
			\end{bmatrix}=(x_{ij})_{3 \times3},
			\ \text{卷积核}\ \mathbf{F}=\begin{bmatrix}  
			1 & -2 \\  
			-1 & 3 
			\end{bmatrix}=(f_{ij})_{2 \times2}$	
		
		根据卷积过程易得输出$\mathbf{O}=\begin{bmatrix}  
				0 & 4 \\  
				14 & 9  
				\end{bmatrix}$  ，${L}=Loss(\mathbf{O})$ 是关于 $\mathbf{O}$ 的某种损失函数。现在假设$\frac{{\partial}L}{{\partial}\mathbf{O}}=\begin{bmatrix}  
					3 & 7 \\  
					6 & 8    
					\end{bmatrix}$，请据此求解$\frac{{\partial}L}{{\partial}x_{11}}$ 和 $\frac{{\partial}L}{{\partial}\mathbf{X}}$	
		\end{itemize} 
\end{exercise}


\begin{exercise}\quad(17分)
	\begin{itemize}
		\item [(1)](5分)判断函数$f(\mathbf{x}) = \max(\|\mathbf{A}\mathbf{x} + \mathbf{b}\|_2, \sqrt{{\mathbf{x}}^T \mathbf{x}} )+\frac{1}{2}{\mathbf{x}}^T\mathbf{P}\mathbf{x}$（其中$\mathbf{A} \in \mathbb{R}^{m \times n}, \, \mathbf{x} \in \mathbb{R}^n, \,\mathbf{b}  \in \mathbb{R}^m $，$\mathbf{P}$为$n$阶半正定矩阵） 是否为凸函数，并说明理由。
		\item [(2)](4分)考虑优化问题 $min f(\mathbf{x})=x_1^2+4x_1x_2$，从初始点$\mathbf{x}^{(0)}=(1,0)^T$出发，写出用梯度下降法迭代一步的过程，迭代时采用精确线搜索方法。
		\item [(3)](4分)利用二阶最优性条件找到问题 $minf(\mathbf{x})=x_1^2+4x_2^2+2x_1x_2$ 的全局最优解。
		\item [(4)](4分)证明 $f(\mathbf{x})=(\stackrel{n}{\underset{k=1}{\prod}}x_k)^{\frac{1}{n}}$，( $\mathbf{x}\in \mathbb{R}^{n}$且 $x_i>0$ ) 是凹函数。
		
		【提示，已知:\\ $\nabla f(\mathbf{x}) = \begin{pmatrix}
			\frac{f(\mathbf{x})}{n x_1}, \frac{f(\mathbf{x})}{n x_2}, \dots, \frac{f(\mathbf{x})}{n x_n}
			\end{pmatrix}^\top ,\quad\nabla^2 f(\mathbf{x}) =- \frac{f(\mathbf{x})}{n^2}
			\begin{bmatrix}
			\frac{n-1}{x_1^2} & -\frac{1}{x_1x_2} & \cdots & -\frac{1}{x_1x_n} \\
			-\frac{1}{x_2x_1} & \frac{n-1}{x_2^2} & \cdots & -\frac{1}{x_2x_n} \\
			\vdots & \vdots & \ddots & \vdots \\
			-\frac{1}{x_nx_1} & -\frac{1}{x_nx_2} & \cdots & \frac{n-1}{x_n^2}
			\end{bmatrix}.$】

	\end{itemize} 
\end{exercise}


\end{document}